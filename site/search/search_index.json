{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Arthur Chan\u2019s AI Advisory Page","text":"<p>Since October 2024, I\u2019ve been working as an advisor and consultant for AI companies. I specialize in speech and language\u2013related technologies, particularly:</p> <ul> <li>Speech Recognition (25+ years of experience)</li> <li>Speech Synthesis</li> <li>Large Language Models (LLMs)</li> <li>Prompt Engineering</li> <li>Natural Language Processing (NLP)</li> </ul> <p>I often work with mid- to late-stage startups and established companies, providing both strategic and technical guidance to support their product and research directions.</p>"},{"location":"#expertise-highlights","title":"Expertise Highlights","text":"<ul> <li>Deep expertise in automatic speech recognition (ASR), from core architecture to production systems  </li> <li>Solid experience with LLMs and generative AI workflows </li> <li>Practical understanding of real-world deployments and product integration</li> </ul>"},{"location":"#leadership-business-experience","title":"Leadership &amp; Business Experience","text":"<ul> <li>One startup exit: Voci Technologies (acquired by Medallia)  </li> <li>Team leadership experience: led a team for over three years in a fast-paced startup environment  </li> </ul> <p>Feel free to DM me on LinkedIn if you have any inquiries or would like to collaborate.</p>"},{"location":"about/","title":"What's up? This is Arthur Chan.","text":"<p>Here\u2019s a short bio of mine:</p> <p>I have been working on speech recognition\u2013related problems (lately rebranded as Conversational AI) for the last 25 years. I was a Staff Scientist at BBN, a Speech Scientist at SpeechWorks (later acquired by Nuance), a Core Technology Scientist at ScanScout (later acquired by Tremor Video), and a Principal Speech Architect at Voci (later acquired by Medallia).</p>"},{"location":"about/#at-cmu","title":"At CMU","text":"<p>I was one of the maintainers of the CMU Sphinx project. I primarily worked on Sphinx 3.X, but later contributed to SphinxTrain as well.</p>"},{"location":"about/#at-voci","title":"At Voci","text":"<p>As Principal Speech Architect, my specialty was maintaining and extending ASR-related software. I was also deeply involved in machine learning tasks such as emotion classification, gender detection, and keyword spotting. I did hands-on coding and led a team of three colleagues.</p>"},{"location":"about/#independent-ai-advisory","title":"Independent AI Advisory","text":"<p>Currently, I\u2019m an AI advisor in the space of Conversational AI \u2014 covering ASR, LLMs, and TTS. Feel free to connect with me on LinkedIn for further inquiries.</p> <p>This page is a revival of my old blog \u2014 The Grand Janitor Blog \u2014 a collection of my thoughts on speech recognition, machine learning, and technology-related topics.</p> <p>Since April 2016, I\u2019ve also curated the Facebook Artificial Intelligence and Deep Learning (AIDL) Forum and its LinkedIn version</p> <p>\u2014 Arthur Chan</p>"},{"location":"ai_portfolio/","title":"AI Portfolio","text":"<p>For the most part, working on machine learning means creating programs that work in real life. In that regard, here are selected systems I've worked on over the years. Noted work is bolded. Not all work is shown \u2014 feel free to contact me if you have questions on specific AI/LLM/deep-learning-related problems. </p>"},{"location":"ai_portfolio/#automatic-speech-recognition-speech-based-ml-systems","title":"\ud83d\udde3\ufe0f Automatic Speech Recognition / Speech-based ML Systems","text":""},{"location":"ai_portfolio/#grad-school-years-20002002","title":"Grad School Years (2000\u20132002)","text":"<ul> <li>Viterbi algorithm implementation that allows skipping exactly K-frames \u2014 featured in several academic papers  </li> <li>Pronunciation learning system, also known as PLACER</li> </ul>"},{"location":"ai_portfolio/#speechworks-20022003","title":"Speechworks (2002\u20132003)","text":"<ul> <li>Cantonese, Singaporean, and Australian English model training for Speechworks 6.5</li> </ul>"},{"location":"ai_portfolio/#carnegie-mellon-university-20032006","title":"Carnegie Mellon University (2003\u20132006)","text":"<ul> <li>Maintainer of CMUSphinx, especially Sphinx3 and SphinxTrain</li> </ul>"},{"location":"ai_portfolio/#scanscout-tremor-20062008","title":"ScanScout / Tremor (2006\u20132008)","text":"<ul> <li>Internal system known as \u201cContent Analyzer\u201d using speech recognition as a backend component</li> </ul>"},{"location":"ai_portfolio/#bbn-technologies-20092011","title":"BBN Technologies (2009\u20132011)","text":"<ul> <li>Unsupervised topic/dialogue classifier based on PTM/Byblos(Hmm-based) segmentation Selected as one of the best papers at Interspeech 2010 </li> <li>British English model training</li> </ul>"},{"location":"ai_portfolio/#voci-technologies-20122023","title":"Voci Technologies (2012\u20132023)","text":"<ul> <li>Architect and Maintainer of Voci\u2019s high-speed speech recognizer, also known as V-Blaze</li> <li>Manager of a three-person team, responsible for language pack delivery</li> <li>General Speech Advisor of the group</li> <li>High-performance keyword spotter</li> <li>Speech-based gender detector</li> <li>Other work - statistical machine translation</li> </ul>"},{"location":"ai_portfolio/#arthur-chan-ai-advisory-2024-now","title":"Arthur Chan AI Advisory (2024-now)","text":"<ul> <li>independent AI advisors</li> <li>Scientific Advisor of C-Level Managers on the matter of Conversational AI.</li> <li>Two major projects:</li> <li>Lead researcher in ASR development for European languages</li> <li>Lead researcher in TTS development for two Asian languages</li> </ul>"},{"location":"contactme/","title":"Contactme","text":"<p>I work for Voci, they produce high-performance speech recognition engine.   If you are looking for an all-round ASR solution for your product, I recommend you to talk with Voci\u2019s representatives.</p> <p>Since I became the admin of AIDL, the PM requests are just overwhelming.   So I would suggest couple of ways you can follow me</p> <p>Visit my personal Facebook Page: Arthur Chan\u2019s Page, Follow me on LinkedIn, Follow me on Plus, Follow me on Twitter, If you need advice or consultation though I would suggest you to talk with me through my clarify.fm account.</p>"},{"location":"fullbio/","title":"About Me","text":""},{"location":"fullbio/#personal-mission-statement","title":"Personal Mission Statement","text":"<p>\"Advancing human language technology and machine learning to deliver practical, impactful, and measurable improvements in everyday life.\"</p>"},{"location":"fullbio/#career-highlights","title":"Career Highlights","text":"<ul> <li>Former Speech Architect of Voci\u2019s speech recognition engine (2012-2023)</li> <li>Former maintainer of the open-source CMU Sphinx project (2004\u20132006)  </li> <li>Early team member at two startups:</li> <li>ScanScout (#4 employee), acquired by Tremor Video in 2010  </li> <li>Voci (#9 employee), later acquired by Medallia  </li> <li>Research staff roles at Raytheon BBN, SpeechWorks (now part of Nuance), ScanScout, and Voci  </li> <li>Co-author of a best paper at a prestigious international conference  </li> </ul>"},{"location":"fullbio/#skills","title":"Skills","text":""},{"location":"fullbio/#programming","title":"Programming","text":"<ul> <li>Languages: C, Perl, Python, C++, Java  </li> <li>Also familiar with web and iOS programming</li> </ul>"},{"location":"fullbio/#conversational-ai","title":"Conversational AI","text":"<p>My expertise spans the full stack of Conversational AI technologies, including automatic speech recognition (ASR), large language models (LLMs), and text-to-speech (TTS).</p> <ul> <li>ASR: Proficient across multiple generations of speech recognition systems, from traditional HMM-based models and HMM-DNN hybrids to modern foundation model\u2013based approaches  </li> <li>TTS: Experienced in fine-tuning state-of-the-art TTS foundation models for custom voice synthesis  </li> <li>LLM: Deep experience with large language models, including prompt engineering, fine-tuning, and applying them to real-world NLP tasks.</li> </ul>"},{"location":"fullbio/#speech-recognition","title":"\ud83d\udde3\ufe0f Speech Recognition","text":"<ul> <li>System architecture (decoder + trainer)</li> <li>Very fast speech recognition</li> <li>Keyword spotting</li> <li>Classification tasks: topic, language, emotion, gender</li> <li>Robust speech recognition</li> </ul> <p>Toolkits used: PyTorch, kaldi, Sphinx (2, 3, 4, PocketSphinx), HTK, Julius, SpeechWorks (pre-OSR 2.0), Byblos, CMULM, SRILM, MITLM, KenLM</p>"},{"location":"fullbio/#deep-learning","title":"Deep Learning","text":"<ul> <li>Large Language Model: Application of LLM on conversational systems, fine-tuning and RAG</li> <li>Speech Recognition: Low-level source-code experience with multiple deep learning toolkits</li> <li>Speech Synthesis: Fine-tuning CosyVoice2 for new language and accent correction.</li> <li>Administration: Setup and deployment of deep learning tools</li> </ul> <p>Toolkits: PyTorch, Tensorflow.</p>"},{"location":"fullbio/#soft-skills","title":"Soft Skills","text":"<ul> <li>Startup experience and MVP building</li> <li>Speech applications and analytics</li> <li>Business use cases of speech recognition and machine learning (especially in startup contexts)</li> <li>Expertise in open-source speech recognition ecosystems</li> </ul>"},{"location":"mlportfoilio/","title":"AI Portfolio","text":"<p>For the most part, working on machine learning means creating programs that work in real life. In that regard, here are selected systems I've worked on over the years. Noted work is bolded. Not all work is shown \u2014 feel free to contact me if you have questions on specific machine learning problems. I may have worked on them before.</p>"},{"location":"mlportfoilio/#automatic-speech-recognition-speech-based-ml-systems","title":"\ud83d\udde3\ufe0f Automatic Speech Recognition / Speech-based ML Systems","text":""},{"location":"mlportfoilio/#grad-school-years-20002002","title":"Grad School Years (2000\u20132002)","text":"<ul> <li>Viterbi algorithm implementation that allows skipping exactly K-frames \u2014 featured in several academic papers  </li> <li>Pronunciation learning system, also known as PLACER</li> </ul>"},{"location":"mlportfoilio/#speechworks-20022003","title":"Speechworks (2002\u20132003)","text":"<ul> <li>Cantonese, Singaporean, and Australian English model training for Speechworks 6.5</li> </ul>"},{"location":"mlportfoilio/#carnegie-mellon-university-20032006","title":"Carnegie Mellon University (2003\u20132006)","text":"<ul> <li>Maintainer of CMUSphinx, especially Sphinx3 and SphinxTrain</li> </ul>"},{"location":"mlportfoilio/#scanscout-tremor-20062008","title":"ScanScout / Tremor (2006\u20132008)","text":"<ul> <li>Internal system known as \u201cContent Analyzer\u201d using speech recognition as a backend component</li> </ul>"},{"location":"mlportfoilio/#bbn-technologies-20092011","title":"BBN Technologies (2009\u20132011)","text":"<ul> <li>Unsupervised topic/dialogue classifier based on PTM/Byblos(Hmm-based) segmentation Selected as one of the best papers at Interspeech 2010 </li> <li>British English model training</li> </ul>"},{"location":"mlportfoilio/#voci-technologies-20122023","title":"Voci Technologies (2012\u20132023)","text":"<ul> <li>Architect and Maintainer of Voci\u2019s high-speed speech recognizer, also known as V-Blaze</li> <li>Manager of a three-person team, responsible for language pack delivery</li> <li>General Speech Advisor of the group</li> <li>High-performance keyword spotter</li> <li>Speech-based gender detector</li> <li>Other work - statistical machine translation</li> </ul>"},{"location":"mlportfoilio/#arthur-chan-ai-advisory-2024x-now","title":"Arthur Chan AI Advisory (2024x-now)","text":"<ul> <li>independent AI advisors</li> <li>Scientific Advisor of C-Level Managers on the matter of Conversational AI.</li> <li>Two major projects -</li> <li>Lead research in ASR development for an European languages</li> <li>Lead research in TTS development in two Asian langauges</li> </ul>"},{"location":"publications/","title":"Publications","text":"<p>Note: \"Yu Chung\" is my Chinese first name.</p>"},{"location":"publications/#selected-papers","title":"\ud83d\udcd1 Selected Papers","text":"<ul> <li> <p>M. Siu, H. Gish, A. Chan, W. Belfield, S. Lowe. Unsupervised training of an HMM-based self-organizing unit recognizer with applications to topic classification and keyword discovery. Computer Speech &amp; Language, 28(1): 210\u2013223 (2014)</p> </li> <li> <p>D. Huggins-Daines, M. Kumar, A. Chan, A. W. Black, R. Mosur, A. I. Rudnicky. PocketSphinx: A Free, Real-time Continuous Speech Recognition System for Hand-held Devices. ICASSP 2006, France ([ps])</p> </li> <li> <p>A. Chan, J. Sherwan, R. Mosur, A. I. Rudnicky. Four-Level Categorization Scheme of Fast GMM Computation Techniques in Large Vocabulary Continuous Speech Recognition Systems. ICSLP 2004, Korea ([ps])</p> </li> <li> <p>A. Chan, M. Siu. Efficient Computation of the Frame-based Extend Union Model and its Application against Partial Temporal Corruptions. Computer Speech and Language, Vol. 19, pp. 301\u2013319 ([ps])</p> </li> <li> <p>M. Siu, A. Chan. A Robust Viterbi Algorithm Against Impulsive Noise with Application for Speech Recognition. IEEE Transactions on Speech and Audio Processing ([final manuscript ps])</p> </li> </ul>"},{"location":"publications/#full-publication-list","title":"\ud83d\udcda Full Publication List","text":"<ul> <li> <p>(See selected list above for highlighted papers)</p> </li> <li> <p>M. Siu, O. Lang, H. Gish, S. Lowe, A. Chan, O. Kimball. MLLR transforms of self-organized units as features in speaker recognition. ICASSP 2012: 4385\u20134388</p> </li> <li> <p>T. J. Hazen, M. Siu, H. Gish, S. Lowe, A. Chan. Topic modeling for spoken documents using only phonetic information. ASRU 2011: 395\u2013400</p> </li> <li> <p>M. Siu, H. Gish, S. Lowe, A. Chan. Unsupervised Audio Patterns Discovery Using HMM-Based Self-Organized Units. INTERSPEECH 2011: 2333\u20132336</p> </li> <li> <p>M. Siu, H. Gish, A. Chan, W. Belfield. Improved topic classification and keyword discovery using an HMM-based speech recognizer trained without supervision. INTERSPEECH 2010: 2838\u20132841</p> </li> <li> <p>H. Gish, M. Siu, A. Chan, W. Belfield. Unsupervised training of an HMM-based speech recognizer for topic classification. INTERSPEECH 2009: 1935\u20131938</p> </li> <li> <p>B. Langner, R. Kumar, A. Chan, L. Gu, A. W. Black. Generating Time-Constrained Audio Presentations of Structured Information. INTERSPEECH 2006, Pittsburgh, USA</p> </li> <li> <p>A. Chan, R. Mosur, A. I. Rudnicky. On Improvements of CI-based GMM Selection. INTERSPEECH 2005, Portugal ([pdf])</p> </li> <li> <p>R. Zhang, Z. Al Bawab, A. Chan, A. Chotiomongkol, D. Huggins-Daines, A. I. Rudnicky. Investigations on Ensemble Based Semi-Supervised Acoustic Model Training. INTERSPEECH 2005, Portugal ([pdf])</p> </li> <li> <p>S. Banerjee, J. Cohen, T. Quisel, A. Chan, Y. Patodia, Z. Al Bawab, R. Zhang, A. Black, R. Stern, R. Rosenfeld, A. I. Rudnicky. Creating Multi-Modal, User-Centric Records of Meetings with the Carnegie Mellon Meeting Recorder Architecture. NIST Meeting Recognition Workshop @ ICASSP 2004</p> </li> <li> <p>Brian Mak, M. Siu, Mimi Ng, Y.-C. Tam, Y. C. Chan, K.-W. Chan, K.-Y. Leung, S. Ho, J. Wong, J. Lo. PLASER: Pronunciation Learning via Automatic Speech Recognition. HLT-NAACL 2003 Workshop on Building Educational Applications using NLP, Edmonton, pp. 23\u201329 ([pdf])</p> </li> <li> <p>M. Siu, Y. C. Chan. Robust Speech Recognition Against Short-Time Noise. ICSLP 2002, Vol. 2, pp. 1049\u20131052 ([ps])</p> </li> <li> <p>M. Siu, Y. C. Chan. A Modified Viterbi Algorithm that Skips K-frames. EUROSPEECH 2001 ([ps])</p> </li> <li> <p>Y. C. Chan, M. Siu, K. W. Mak. Pruning of the State-Tying Tree using the Bayesian Information Criterion with Multiple Mixtures. ICSLP 2000, Vol. 4, pp. 294\u2013297 ([ps])</p> </li> </ul>"},{"location":"publications/#volunteer-work-at-mgh","title":"\u2764\ufe0f Volunteer Work at MGH","text":"<ul> <li>C. J. Chu, A. Chan, D. Song, K. J. Staley, S. M. Stufflebeam, M. A. Kramer. Semi-automated method for rapid detection of ripple events on interictal voltage discharges in the scalp electroencephalogram. Journal of Neuroscience Methods, Vol. 277, Feb 2017, pp. 46\u201355</li> </ul>"}]}